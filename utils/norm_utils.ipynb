{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.sandbox.stats import multicomp\n",
    "\n",
    "# import other utils\n",
    "sys.path.append(\"../../utils\")\n",
    "from misc_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalizing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pseudocount(df):\n",
    "    pseudo = pd.DataFrame()\n",
    "    try:\n",
    "        pseudo[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        pseudo[\"element\"] = df[\"element\"]\n",
    "    for col in df.columns:\n",
    "        if col not in [\"barcode\", \"element\"]:\n",
    "            pseudo[col] = df[col] + 1\n",
    "    return pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_cpm(df):\n",
    "    cpm = pd.DataFrame()\n",
    "    try:\n",
    "        cpm[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        cpm[\"element\"] = df[\"element\"]\n",
    "    for col in df.columns:\n",
    "        if col not in [\"barcode\", \"element\"]:\n",
    "            cpm[col] = df[col]/np.nansum(df[col])*1e6\n",
    "    return cpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_activ(df):\n",
    "    # assumes there is only 1 dna replicate -- will have to edit if more than one\n",
    "    activ = pd.DataFrame()\n",
    "    try:\n",
    "        activ[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        activ[\"element\"] = df[\"element\"]\n",
    "    for col in df.columns:\n",
    "        if col not in [\"barcode\", \"element\", \"dna_1\"]:\n",
    "            activ[col] = df[col]/df[\"dna_1\"] \n",
    "    return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_log2(df):\n",
    "    log2 = pd.DataFrame()\n",
    "    try:\n",
    "        log2[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        log2[\"element\"] = df[\"element\"]\n",
    "    for col in df.columns:\n",
    "        if col not in [\"barcode\", \"element\"]:\n",
    "            log2[col] = np.log2(df[col])\n",
    "    return log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_norm(df):\n",
    "    norm = pd.DataFrame()\n",
    "    try:\n",
    "        norm[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        norm[\"element\"] = df[\"element\"]\n",
    "    for col in df.columns:\n",
    "        if col not in [\"barcode\", \"element\"]:\n",
    "            norm[col] = df[col] - np.nanmedian(df[col])\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantile_norm(df):\n",
    "    quant = pd.DataFrame()\n",
    "    try:\n",
    "        quant[\"barcode\"] = df[\"barcode\"]\n",
    "    except:\n",
    "        quant[\"element\"] = df[\"element\"]\n",
    "    df_num = df.drop(\"barcode\", axis=1)\n",
    "    rank_mean = df_num.stack().groupby(df_num.rank(method='first').stack().astype(int)).mean()\n",
    "    tmp = df_num.rank(method='min').stack().astype(int).map(rank_mean).unstack()\n",
    "    quant = pd.concat([quant, tmp], axis=1)\n",
    "    return quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def element_p_val_per_rep_neg_controls(df, reps, min_barc, neg_ctrl_cols, tile_types_to_check):\n",
    "    \"\"\"\n",
    "    function to grab a pvalue for an element of interest (via wilcox) as it compares to negative controls\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp.sort_values(by=\"element\", ascending=True)\n",
    "    unique_elems = tmp[tmp.better_type.isin(tile_types_to_check)][\"element\"].unique()\n",
    "    print(\"checking %s unique elements\" % (len(unique_elems)))\n",
    "    us = {}\n",
    "    pvals = {}\n",
    "    fcs = {}\n",
    "    for i, elem in enumerate(unique_elems):\n",
    "        rep_us = {}\n",
    "        rep_pvals = {}\n",
    "        rep_fcs = {}\n",
    "        for rep in reps:\n",
    "            tmp_sub = tmp[tmp[\"element\"] == elem]\n",
    "            \n",
    "            dist = np.asarray(tmp_sub[rep])\n",
    "            null_dist = np.asarray(tmp[tmp[\"better_type\"].isin(neg_ctrl_cols)][rep])\n",
    "            \n",
    "            n_non_nas = np.count_nonzero(~np.isnan(dist))\n",
    "            n_non_null_nas = np.count_nonzero(~np.isnan(null_dist))\n",
    "            \n",
    "            if n_non_nas < min_barc or n_non_null_nas < min_barc:\n",
    "                u, pval = np.nan, np.nan\n",
    "            else:\n",
    "                non_na_dist = dist[~np.isnan(dist)]\n",
    "                non_na_null = null_dist[~np.isnan(null_dist)]\n",
    "                \n",
    "                u, pval = stats.mannwhitneyu(non_na_dist, non_na_null, alternative=\"two-sided\", use_continuity=False)   \n",
    "            median_dist = np.nanmedian(dist)\n",
    "            fc = median_dist - np.nanmedian(null_dist)\n",
    "            rep_us[rep] = u\n",
    "            rep_pvals[rep] = pval\n",
    "            rep_fcs[rep] = fc\n",
    "            \n",
    "        us[elem] = rep_us\n",
    "        pvals[elem] = rep_pvals\n",
    "        fcs[elem] = rep_fcs\n",
    "        \n",
    "        if i % 250 == 0:\n",
    "            print(\"...elem %s... %s\" % (i, time.ctime()))\n",
    "    return us, pvals, fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_pvals(row, reps):\n",
    "    pvals = np.asarray(list(row[reps]))\n",
    "    non_na_pvals = np.asarray([float(x) for x in pvals if not \"NA\" in str(x)])\n",
    "    non_na_pvals = non_na_pvals[~np.isnan(non_na_pvals)]\n",
    "    if len(non_na_pvals) > 1:\n",
    "        new_pval = stats.combine_pvalues(non_na_pvals, method=\"stouffer\")[1]\n",
    "    else:\n",
    "        new_pval = np.nan\n",
    "    return new_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sig_combined(row, col, thresh, l2fc_cols):\n",
    "    if pd.isnull(row[col]):\n",
    "        return row[col]\n",
    "    elif row[col] < thresh:\n",
    "        l2fcs = list(row[l2fc_cols])\n",
    "        neg = [x for x in l2fcs if x < 0]\n",
    "        pos = [x for x in l2fcs if x > 0]\n",
    "        perc_neg = len(neg)/float(len(neg)+len(pos))\n",
    "        perc_pos = len(pos)/float(len(neg)+len(pos))\n",
    "        if perc_neg > 0.75 or perc_pos > 0.75:\n",
    "            return \"sig\"\n",
    "        else:\n",
    "            return \"not sig\"\n",
    "    else:\n",
    "        return \"not sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsamp_is_sig_combined(row, samp_combined_cols, n_samples):\n",
    "    vals = list(row[samp_combined_cols])\n",
    "    n_sig_samples = len([x for x in vals if x == \"sig\"])\n",
    "    if n_sig_samples > 0.75 * n_samples:\n",
    "        return \"sig\"\n",
    "    else:\n",
    "        return \"not sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_active_or_repressive(row, sig_col, thresh, l2fc_cols):\n",
    "    if row[sig_col] == \"sig\":\n",
    "        mean_l2fc = np.mean(row[l2fc_cols])\n",
    "        if mean_l2fc >= thresh:\n",
    "            return \"sig active\"\n",
    "        elif mean_l2fc <= -thresh:\n",
    "            return \"sig repressive\"\n",
    "        else:\n",
    "            return \"not sig\"\n",
    "    else:\n",
    "        return \"not sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downsamp_is_active_or_repressive(row, sig_col, samp_class_cols):\n",
    "    if row[sig_col] == \"sig\":\n",
    "        vals = list(row[samp_class_cols])\n",
    "        n_active = vals.count(\"sig active\")\n",
    "        n_repressive = vals.count(\"sig repressive\")\n",
    "        if n_active > n_repressive:\n",
    "            return \"sig active\"\n",
    "        elif n_repressive > n_active:\n",
    "            return \"sig repressive\"\n",
    "        else:\n",
    "            return \"not sig\"\n",
    "    else:\n",
    "        return \"not sig\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
