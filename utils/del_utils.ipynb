{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.sandbox.stats import multicomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME_DICT = {\"CDKN2B-AS\": \"ANRIL\", \"ZNFX1-AS1\": \"ZFAS1\", \"FLJ43663\": \"LINC_PINT\", \"LOC400550\": \"FENDRR\", \n",
    "             \"ENST00000416894\": \"FALEC\", \"ENST00000483525\": \"SAMMSON\", \"ENST00000513626\": \"LUCAT1\"}\n",
    "LOC_DICT = {\"chr16:86543137..86543345\": \"FOXF1\", \"chr20:47893097..47893305\": \"enhancer_ZFAS1\", \n",
    "            \"chr3:169482079..169482287\": \"enhancer_TERC\", \"chr7:130796089..130796297\": \"enhancer_LINC_PINT\", \n",
    "            \"chr11:65187510..65187718\": \"enhancer_NEAT1\", \"chr11:65265021..65265229\": \"enhancer_MALAT1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_DEL_BASES = 94\n",
    "N_DEL_START = 11\n",
    "N_DEL_END = 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_del_num(row):\n",
    "    if \"DELETION\" in row.unique_id:\n",
    "        del_num = int(row.unique_id.split(\".\")[-2])\n",
    "    else:\n",
    "        del_num = 0\n",
    "    return del_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_del_base(row, seq_map):\n",
    "    if \"DELETION\" in row.oligo_type:\n",
    "        seq = seq_map[row.element]\n",
    "        base = seq[row.del_num-1]\n",
    "    else:\n",
    "        base = \"X\"\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_dupe_info(row):\n",
    "    \"\"\"\n",
    "    this function is only necessary because i did the dupe_info column stupidly in this index.\n",
    "    need to put in format where the dupe_info always contains one value (its tile_id), \n",
    "    and if there is a dupe, a comma-separated list of them.\n",
    "    \"\"\"\n",
    "    new_oligo_id = \".\".join(row.oligo_id.split(\".\")[:-1])\n",
    "    if row.dupe_info == \"none\":\n",
    "        return new_oligo_id\n",
    "    else:\n",
    "        return \"%s,%s\" % (new_oligo_id, row.dupe_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_barcode_value_map(element_data, barcode_data, reps):\n",
    "    \n",
    "    barcode_value_dict = {}\n",
    "    \n",
    "    dels = element_data[element_data[\"oligo_type\"].str.contains(\"DELETION\")][[\"element\", \"tile_name\", \"oligo_type\"]].drop_duplicates()\n",
    "    barc_dels = barcode_data[barcode_data[\"oligo_type\"].str.contains(\"DELETION\")]\n",
    "    barc_wt_w_snp = barcode_data[barcode_data[\"oligo_type\"] == \"WILDTYPE_BUT_HAS_SNP\"]\n",
    "    barc_wt = barcode_data[barcode_data[\"oligo_type\"] == \"WILDTYPE\"]\n",
    "    barc_fl = barcode_data[barcode_data[\"oligo_type\"] == \"FLIPPED\"]\n",
    "    \n",
    "    print(\"mapping barcode values to %s deletion sequences\" % (len(dels.element.unique())))\n",
    "    \n",
    "    counter = 0\n",
    "    for i, row in dels.iterrows():\n",
    "        if counter % 1000 == 0:\n",
    "            print(\"..row %s..\" % counter)\n",
    "        dels_df = barc_dels[barc_dels[\"element\"] == row.element]\n",
    "        rep_dict = {}\n",
    "        for rep in reps:\n",
    "            del_vals = list(dels_df[rep])\n",
    "            if \"WILDTYPE_BUT_HAS_SNP\" in row.oligo_type:\n",
    "                wt_df = barc_wt_w_snp[barc_wt_w_snp[\"tile_name\"] == row.tile_name]\n",
    "                wt_vals = list(wt_df[rep])\n",
    "            elif \"WILDTYPE\" in row.oligo_type:\n",
    "                wt_df = barc_wt[barc_wt[\"tile_name\"] == row.tile_name]\n",
    "                wt_vals = list(wt_df[rep])\n",
    "            elif \"FLIPPED\" in row.oligo_type:\n",
    "                wt_df = barc_fl[barc_fl[\"tile_name\"] == row.tile_name]\n",
    "                wt_vals = list(wt_df[rep])\n",
    "            rep_dict[rep] = (wt_vals, del_vals)\n",
    "            \n",
    "        barcode_value_dict[row.element] = rep_dict\n",
    "        counter += 1\n",
    "        \n",
    "    return barcode_value_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_p_value(barcode_value_dict):\n",
    "    seqs = barcode_value_dict.keys()\n",
    "    print(\"calculating pvalues b/w deletion and wt for %s deletion tiles\" % (len(seqs)))\n",
    "    pvals = {}\n",
    "    l2fcs = {}\n",
    "    for seq in seqs:\n",
    "        rep_pvals = {}\n",
    "        rep_l2fcs = {}\n",
    "        seq_data = barcode_value_dict[seq]\n",
    "        for rep in seq_data.keys():\n",
    "            rep_data = seq_data[rep]\n",
    "            wt = np.asarray(rep_data[0])\n",
    "            deletion = np.asarray(rep_data[1])\n",
    "            wt = wt[~np.isnan(wt)]\n",
    "            deletion = deletion[~np.isnan(deletion)]\n",
    "            wt_med = np.median(wt)\n",
    "            del_med = np.median(deletion)\n",
    "            l2fc = del_med - wt_med\n",
    "            u, pval = stats.mannwhitneyu(wt, deletion, alternative=\"two-sided\", use_continuity=False)\n",
    "            rep_pvals[rep] = pval\n",
    "            rep_l2fcs[rep] = l2fc\n",
    "        pvals[seq] = rep_pvals\n",
    "        l2fcs[seq] = rep_l2fcs\n",
    "    return pvals, l2fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_pvals(row, reps):\n",
    "    pvals = np.asarray(list(row[reps]))\n",
    "    non_na_pvals = pvals[~np.isnan(pvals)]\n",
    "    if len(non_na_pvals) > 1:\n",
    "        new_pval = stats.combine_pvalues(non_na_pvals, method=\"stouffer\")[1]\n",
    "    else:\n",
    "        new_pval = np.nan\n",
    "    return new_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sig_combined(row, col, thresh, l2fc_cols):\n",
    "    if pd.isnull(row[col]):\n",
    "        return row[col]\n",
    "    elif row[col] < thresh:\n",
    "        l2fcs = list(row[l2fc_cols])\n",
    "        neg = [x for x in l2fcs if x < 0]\n",
    "        pos = [x for x in l2fcs if x > 0]\n",
    "        perc_neg = len(neg)/float(len(neg)+len(pos))\n",
    "        perc_pos = len(pos)/float(len(neg)+len(pos))\n",
    "        if perc_neg > 0.75 or perc_pos > 0.75:\n",
    "            return \"sig\"\n",
    "        else:\n",
    "            return \"not sig\"\n",
    "    else:\n",
    "        return \"not sig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_and_adjust_pvals(pvals_dict, l2fcs_dict, alpha, reps):\n",
    "    # turn into dfs\n",
    "    pvals_df = pd.DataFrame.from_dict(pvals_dict, orient=\"index\")\n",
    "    l2fcs_df = pd.DataFrame.from_dict(l2fcs_dict, orient=\"index\")\n",
    "    pvals_df.columns = [\"%s_pval\" % x for x in pvals_df.columns]\n",
    "    l2fcs_df.columns = [\"%s_l2fc\" % x for x in l2fcs_df.columns]\n",
    "\n",
    "    # combine pvals\n",
    "    pvals_df[\"combined_pval\"] = pvals_df.apply(combine_pvals, reps=pvals_df.columns, axis=1)\n",
    "\n",
    "    # adjust combined pvals\n",
    "    pvals_nonan_df = pvals_df[~pd.isnull(pvals_df[\"combined_pval\"])]\n",
    "    pvals_nonan_df[\"combined_padj\"] = multicomp.multipletests(pvals_nonan_df[\"combined_pval\"], method=\"bonferroni\")[1]\n",
    "\n",
    "    # put all in one df\n",
    "    pvals_df.reset_index(inplace=True)\n",
    "    l2fcs_df.reset_index(inplace=True)\n",
    "    pvals_nonan_df.reset_index(inplace=True)\n",
    "    all_pvals = pvals_df.merge(l2fcs_df, on=\"index\", how=\"outer\")\n",
    "    all_pvals = all_pvals.merge(pvals_nonan_df[[\"index\", \"combined_padj\"]], on=\"index\", how=\"left\")\n",
    "\n",
    "\n",
    "    # see if it's combined sig\n",
    "    all_pvals[\"combined_sig\"] = all_pvals.apply(is_sig_combined, col=\"combined_padj\", thresh=alpha, \n",
    "                                                l2fc_cols=[\"%s_l2fc\" % x for x in reps], axis=1)\n",
    "    return all_pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pval(row, pval_dict, dict_col):\n",
    "    if row.element in pval_dict.keys():\n",
    "        return pval_dict[row.element][dict_col]\n",
    "    else:\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tidy_split(df, column, sep='|', keep=False):\n",
    "    \"\"\"\n",
    "    Split the values of a column and expand so the new DataFrame has one split\n",
    "    value per row. Filters rows where the column is missing.\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    df : pandas.DataFrame\n",
    "        dataframe with the column to split and expand\n",
    "    column : str\n",
    "        the column to split and expand\n",
    "    sep : str\n",
    "        the string used to split the column's values\n",
    "    keep : bool\n",
    "        whether to retain the presplit value as it's own row\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Returns a dataframe with the same columns as `df`.\n",
    "    \"\"\"\n",
    "    indexes = list()\n",
    "    new_values = list()\n",
    "    df = df.dropna(subset=[column])\n",
    "    for i, presplit in enumerate(df[column].astype(str)):\n",
    "        values = presplit.split(sep)\n",
    "        if keep and len(values) > 1:\n",
    "            indexes.append(i)\n",
    "            new_values.append(presplit)\n",
    "        for value in values:\n",
    "            indexes.append(i)\n",
    "            new_values.append(value)\n",
    "    new_df = df.iloc[indexes, :].copy()\n",
    "    new_df[column] = new_values\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_del_num(row):\n",
    "    try:\n",
    "        dupe_num = int(row.dupe_info.split(\".\")[-2])\n",
    "        if row.del_num == dupe_num:\n",
    "            return row.del_num\n",
    "        else:\n",
    "            return dupe_num\n",
    "    except:\n",
    "        return row.del_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wrangle_deletion_data(df, unique_names, wt_pvals):\n",
    "    all_dels = {}\n",
    "    for uniq in unique_names:\n",
    "\n",
    "        dels = df[(df[\"tile_name\"] == uniq) & (df[\"oligo_type\"].str.contains(\"DELETION\"))]\n",
    "        wt = df[(df[\"tile_name\"] == uniq) & (df[\"oligo_type\"].isin([\"WILDTYPE\", \"FLIPPED\", \"WILDTYPE_BUT_HAS_SNP\"]))][\"element\"].iloc[0]\n",
    "        wt_id = df[(df[\"tile_name\"] == uniq) & (df[\"oligo_type\"].isin([\"WILDTYPE\", \"FLIPPED\", \"WILDTYPE_BUT_HAS_SNP\"]))][\"unique_id\"].iloc[0]\n",
    "        \n",
    "        wt_pval = wt_pvals[wt_pvals[\"unique_id\"] == wt_id][\"combined_padj\"].iloc[0]\n",
    "        l2fc_cols = [x for x in wt_pvals.columns if \"_log2fc\" in x]\n",
    "        wt_l2fc = wt_pvals[wt_pvals[\"unique_id\"] == wt_id][l2fc_cols].mean(axis=1).iloc[0]\n",
    "        wt_class = wt_pvals[wt_pvals[\"unique_id\"] == wt_id][\"combined_class\"].iloc[0]\n",
    "        \n",
    "        wt_activ = df[(df[\"tile_name\"] == uniq) & (df[\"oligo_type\"].isin([\"WILDTYPE\", \"FLIPPED\", \"WILDTYPE_BUT_HAS_SNP\"]))][\"overall_mean\"].iloc[0]\n",
    "        tile_chr = df[df[\"unique_id\"] == wt_id][\"chr\"].iloc[0]\n",
    "        tile_start = df[df[\"unique_id\"] == wt_id][\"tile_start\"].iloc[0]\n",
    "        tile_end = df[df[\"unique_id\"] == wt_id][\"tile_end\"].iloc[0]\n",
    "        \n",
    "        del_l2fc_cols = [x for x in dels.columns if \"_l2fc\" in x]\n",
    "        dels[\"mean.log2FC\"] = dels[del_l2fc_cols].mean(axis=1)\n",
    "        dels[\"lfcSD\"] = dels[del_l2fc_cols].std(axis=1)\n",
    "        dels[\"lfcSE\"] = dels[del_l2fc_cols].std(axis=1)/np.sqrt(len(del_l2fc_cols))\n",
    "        dels_sub = dels[[\"del_num_fixed\", \"mean.log2FC\", \"lfcSD\", \"lfcSE\", \"del_base\", \"combined_padj\", \"combined_sig\"]]\n",
    "        dels_sub[\"wt_activ\"] = wt_activ\n",
    "        dels_sub[\"wt_l2fc\"] = wt_l2fc\n",
    "        dels_sub[\"wt_class\"] = wt_class\n",
    "        dels_sub[\"tile_chr\"] = tile_chr\n",
    "        dels_sub[\"tile_start\"] = tile_start\n",
    "        dels_sub[\"tile_end\"] = tile_end\n",
    "        \n",
    "        # deal with missing bases\n",
    "        if len(dels_sub) != N_DEL_BASES:\n",
    "            missing_bases = [x for x in range(N_DEL_START, N_DEL_END+1) if x not in list(dels_sub[\"del_num_fixed\"])]\n",
    "            if len(missing_bases) > 0:\n",
    "                print(\"%s is missing %s bases: %s\" % (uniq, len(missing_bases), missing_bases))\n",
    "            for i in missing_bases:\n",
    "                wt = df[(df[\"tile_name\"] == uniq) & (df[\"oligo_type\"].isin([\"WILDTYPE\", \n",
    "                                                                            \"FLIPPED\", \n",
    "                                                                            \"WILDTYPE_BUT_HAS_SNP\"]))][\"element\"].iloc[0]\n",
    "                base = wt[i-1]\n",
    "                dels_sub = dels_sub.append({\"del_num_fixed\": i, \"mean.log2FC\": np.nan, \"lfcSD\": np.nan, \"lfcSE\": np.nan, \n",
    "                                            \"del_base\": base, \"wt_activ\": wt_activ, \"wt_l2fc\": wt_l2fc, \n",
    "                                            \"wt_class\": wt_class, \"tile_chr\": tile_chr, \n",
    "                                            \"tile_start\": tile_start, \"tile_end\": tile_end}, \n",
    "                                           ignore_index=True)\n",
    "        dels_sub = dels_sub.sort_values(by=\"del_num_fixed\", ascending=True)\n",
    "        assert(len(dels_sub) == N_DEL_BASES)\n",
    "        dels_sub.columns = [\"delpos\", \"mean.log2FC\", \"sd\", \"se\", \"seq\", \"padj\", \"sig\", \"wt_activ\", \"wt_l2fc\", \"wt_class\",\n",
    "                            \"tile_chr\", \"tile_start\", \"tile_end\"]\n",
    "        all_dels[uniq] = dels_sub\n",
    "    return all_dels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_names(key, cell_type, data, name_dict, loc_dict):\n",
    "    tile_row = data[(data[\"tile_name\"] == key) & (data[\"oligo_type\"].str.contains(\"DELETION\"))].iloc[0]\n",
    "    chrom = tile_row[\"chr\"]\n",
    "    start = int(tile_row[\"tile_start\"])\n",
    "    end = int(tile_row[\"tile_end\"])\n",
    "    strand = tile_row[\"strand\"]\n",
    "    locs = \"%s:%s-%s\" % (chrom, start, end)\n",
    "    if strand == \"+\":\n",
    "        text_strand = \"plus\"\n",
    "    else:\n",
    "        text_strand = \"minus\"\n",
    "    tile_num = int(tile_row[\"tile_number\"])\n",
    "    \n",
    "    name = key.split(\"__\")[1]\n",
    "    coords = key.split(\"__\")[2].split(\",\")[0]\n",
    "    \n",
    "    try:\n",
    "        gene = name.split(\",\")[0].split(\"@\")[1]\n",
    "        prom = name.split(\",\")[0].split(\"@\")[0]\n",
    "    except:\n",
    "        gene = \"X\"\n",
    "        prom = \"pX\"\n",
    "    \n",
    "    if gene not in name_dict.keys() and coords not in loc_dict.keys():\n",
    "        name = \"%s__%s__tile%s\" % (gene, prom, tile_num)\n",
    "    elif gene in name_dict.keys():\n",
    "        name = \"%s__%s__tile%s\" % (name_dict[gene], prom, tile_num)\n",
    "    elif coords in loc_dict.keys():\n",
    "        name = \"%s__%s__tile%s\" % (loc_dict[coords], prom, tile_num)\n",
    "    \n",
    "    filename = \"%s.%s.%s.av.log2FC.%s.txt\" % (name, locs, text_strand, cell_type)\n",
    "    clean_name = \"%s__%s\" % (name, text_strand)\n",
    "    return filename, clean_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
